application canister: A distributed application—usually written by a third-party developer or organization—that has been compiled into a WebAssembly (wasm) module and deployed as a canister on the Internet Computer platform. This terminology was originally used to distinguish between user-facing programs deployed as canisters and system management services deployed as canisters. It is important to note, however, that an application’s functions might be contained within a single canister or be split into multiple canisters depending on design and implementation decisions made by the application developer. Therefore, an application canister might represent a program that can be accessed directly by a user or a program that provides services to other user-accessible programs. In general, this term is only used in legacy documentation and deprecated in favor or application to describe a software feature set or canister to describe a deployed computational unit.
application state: Compiled WASM module implementing the canister’s functionality and its dependent modules, together with an instance of each of the modules.
artifact:
artifact pool:
batch: A set of messages with an agreed-upon order by a sufficient number of replica that have been finalized by consensus and are available for the message routing layer to add to the induction pool.
canister: A computational unit that consists of both code and state with a unique identifier—the canisterId—that is compiled into a WebAssembly (wasm) module. After code and state are compiled into a canister, the canister can be deployed on the Internet Computer platform and accessed over the network.
canister identifier: A globally-unique identifier that is registered on a subnet before code is deployed on the Internet Computer platform.
canister owner: Deprecated terminology for the person or entity that can upgrade or mark a canister as See *controller*.
canister pool: The collection of all canisters on any given subnet.
canister messages: A message sent from one canister to another. Note that a canister message can be an application-generated message sent from one canister to another or a system-generated message sent from one canister to another and that the canisters can be on the same or different subnets. This type of message is also referred to as a *canister-to-canister* message or an *inter-canister* call.
canister migration: The system services and components that interact with the replica and NetOS to enable application canisters to be moved from one subnet to another. CanisterMigration is a subcomponent of NetOS (and part of the replica) involved in migrating application canisters from one subnet to another.
canister state: The entire current state of a canister, consisting of the application state and the system state, and the canister’s code (excluding the Input and OutputQueues).
certified non-mutating query: A query call that reads data from a node that has been cryptographically certified by a quorum of nodes.
certified variables: Global variables that are signed by the hosting subnet after each round, such that it can be exposed to users much faster than the rest of the canister state.
consensus: In distributed computing, consensus is a fault tolerant mechanism by which a sufficient number of processes in a group can reach agreement about a value or state. For the Internet Computer, consensus is a core component of the replica software. The consensus layer selects messages from the peer-to-peer artifact pool and pulls messages from the cross-network streams of other subnets and organizes them into a message batch with a sequence that sufficiently many replicas agree upon before the batch is delivered to the message routing layer.
container:
controller: The person, organization, or canister that has administrative rights to control operations for another canister. For example, the controller for a canister can control whether the canister can be upgraded or marked as permanent. The controller is a canister property that supports autonomous software operation.
CUP (Catch Up Package): Contains all necessary data to bootstrap a subnet participant
cycles: Represents the unit of measurement for resources consumed in the form of processing time, memory an application requires for storage, and network bandwidth. The cycles used to pay for resources consumed are held in an account on behalf of a user or an application.The Internet Computer native currency (ICP tokens) can be converted to cycles and transferred to an application account to ensure the application has the resources required to perform its services. Cycles can also be transferred directly from one application to another.
data center provider:
default canister: Application canisters built from a canister library provided by the Internet Computer network.
DFN: **Deprecated** terminology for the Internet Computer native currency. The native currency was previously referred to as DFINITY Network tokens or as DFN. The native currency is now referred to as ICP tokens.
distributed key generation (DKG):
epoch: Represents the number of consecutive consensus rounds that is longer (with a very high probability) than potential forks can survive.
eventual consistency: In principle, eventual consistency means that—without further input to the system—there is a point in the future when all replicas will agree on what they consider the truth. Achieving eventual consistency typically involves: 1. Replicating data across participants. 2. Performing updates locally on each participant. 3. Propagating local updates to other participants asynchronously when connections are available. On the Internet Computer platform, however, eventual consistency for the peer-to-peer layer is intended to reflect a guarantee that valid artifacts will reach all honest nodes within a bounded time period. In this context, eventual consistency is subject to assumptions on bandwidth and about artifacts that are actively dropped. Within these constraints, eventual consistency for the Internet Computer does not require or imply that all artifacts in the artifact pool across all artifact pools in all nodes will be identical.
execution cycle: An event invoked by the message routing scheduler upon receipt of a new InputBlock during which it executes as much of the induction pool as possible
execution environment: For the Internet Computer, the execution environment is a core component of the replica software. The execution environment provides a runtime environment for executing WebAssembly modules. After the message routing layer identifies the canister that will handle processing for an ingress message, the execution environment processes the message in the order in which it receives it.
gas: **Deprecated** terminology that represents the unit of measurement for resources consumed in the form of processing time, memory an application requires for storage, and network bandwidth. The gas used to pay for resources consumed by a canister is held in an account on behalf of a user or an application.
gossip protocol: A gossip protocol is a common approach to communication for distributed systems that is analogous to how information spreads from person to person in a social network. With a gossip protocol, information spreads from computer to computer in the form of  broadcast messages with each computer only disseminating the information to its network neighbors. For the Internet Computer, gossip is used in the peer-to-peer layer of the replica to advertise the artifacts the replica has received to the neighboring peers it has been assigned**.**
HTTP handler:
induction pool: Collection of input queues of all canisters on a subnet.
ingress message: A message sent by an end-user to an application canister that is routed through consensus.
ingress message history: Records every processed ingress message with a boolean flag to indicate whether it was successfully included in the induction pool or not and, potentially, the response..
input batch queue: Ordered sequence of blocks produced by the Consensus component
input pool: Collection of ingress message.
Input queue: Contains canister to canister messages. Held by the receiving canister.
input stream:
inter-canister message: A message sent from one canister to another. Inter-canister messages might be initiated on behalf of a user but are distinct from user-initiated *ingress messages*. Note that a canister message can be an application-generated message sent from one canister to another or a system-generated message sent from one canister to another and that the canisters can be on the same or different subnets. This type of message is also referred to as a *canister-to-canister* message or an *inter-canister* call.
Internet Computer: The **Internet Computer** is a decentralized platform that enables a global network of connected computers to provide scalable computing capacity for running application software.
Internet Computer nervous system (ICNS): **Deprecated** terminology for the Internet Computer governance system. See *network nervous system (NNS)*.
Internet Compute Provider (ICP): **Deprecated** terminology for data center providers. See *data center providers*.
Internet Compute Provider Identity (ICPId): **Deprecated** terminology for the identifier associated with each data center provider. See *data center providers*.
mainnet: Deprecated terminology for the platform management network. See *network nervous system* and *registry*.
message: Data sent from one canister to another, from a user to a canister, or between system components.
message routing: For the Internet Computer, message routing is a core component of the replica software. The message routing layer receives the message batches from the consensus layer, extracts the messages in order, and schedules the messages for execution. After messages are executed, the message routing layer takes any messages produced in the execution cycle from the application output queues and puts those messages into the outgoing streams to be consumed by canisters on other subnets.
mutating call: A “write” call that changes the state of the queried canister.
neighboring peers: The replicas that exchange gossip with each other based on their network overlay topology.
network nervous system (NNS) / network neural system (NNS): The native governance system for the Internet Computer platform. The network nervous system provides global configuration and sub-network specific information to manage updates to the replicas, subnets, and canisters deployed and to handle system change proposals and voting.
neuron: An entity that can make proposals and vote on proposals related to governance of the Internet Computer platform. To provide the stability required for responsible governance, DFINITY (DFN) tokens can be converted to **neurons**. A neuron represents a number of DFN tokens that cannot be exchanged for a minimum period of time (the lock-up period). When a person or organization has some number of DFN tokens locked up in a neuron, the neuron holder has the right to propose and vote on governance issues, and to be paid for voting in proportion to the number of DFN locked up and the length of the lock-up period.
node: A node is a physical or virtual network endpoint that hosts all the hardware, software, and configuration settings required to participate in the Internet Computer network.
node identifier:
non-mutating query: A “read” operation call that does not change the state of the queried canister. More commonly, this type of operation is simply referred to as a *query*.
orthogonal persistence:
output pool: Collection of output queues of all canisters on a subnet.
output queue: Contains canister to canister messages. Held by the sending canister.
output stream: A sequence of output messages from the different canister output queues.
overlay network:
peer-to-peer: In common usage, peer-to-peer (P2P) computing or networking is a distributed application architecture that partitions workload across s network of equally-privileged computer nodes so that participants can contribute resources such as processing power, disk storage, or network bandwidth to handle application workload. For the Internet Computer, peer-to-peer is a core component of the replica software. The peer-to-peer layer collects and advertises messages and artifacts from users and from other nodes in its sub-network. The primary purpose of the peer-to-peer layer is to make the artifact pool consistent across all of the replicas in a given subnet before sequencing by consensus.
pre-processing: Phase triggered by a new InputBlock during which the Message Routing component puts the Ingress messages and canister messages from the subnet streams into the Induction Pool as appropriate, updates the IngressMsgHistory, manages the OutputQueue and creates SignalingMessages as a reaction to XNet CanisterMessages.
post-processing: Once execution is finished, the message routing layer produces a new set of output streams from the output pool.
query: A call optimized to allow read-only operations or to perform transient state changes in which the canister state **is not preserved**. - Are synchronous and can be made to any node that holds the canister. - Do not require consensus to verify the result. There is an inherent tradeoff between security and performance because the reply from a single node might be untrustworthy or inaccurate.
replica: The set of protocol components that are necessary for a node to participate in a network.
registry:
rotating log: Deprecated terminology for where information about user-generated update call is recorded. See *ingress message history*.
signal messages: Acknowledge receipt of messages sent on behalf of a canister - ERROR: SignalingMessage that indicates that a Xnet canister message has been rejected - ACK: SignalingMessage that indicates that a Xnet canister message has been processed
signaling stream:
state change: A state change is the result of any transaction, function call, or operation that changes the information stored for an application. For example, if a function makes an update call that adds two numbers together or removes a name from a list, the result is a change to the application state.
state manager:
sub-network / subnet: An instance of the Internet Computer network that hosts and runs software canisters. The Internet Computer relies on a network of **connected computers** that communicate securely to provide computing capacity. Groups of connected computers are organized into multiple smaller networks—called **sub-networks** or **subnets**—for servicing requests. The individual physical or virtual computers in a subnet are called **nodes.** Subnets and nodes provide a distributed network that is managed through independently-operated data centers. Each sub-network acts on its own and is registered in a global **registry**. The distributed and decentralized architecture enables multiple connected computers to operate like a single very powerful virtual machine.
subnet protocol replica: The set of protocol components that are necessary for a node to participate in a subnet.
system canister: A pre-installed Canister shipped with the DFINITY network that performs certain tasks needed to maintain the system.
system state: Auxiliary state of a canister that is maintained by the system on behalf of the canister, including DFN balance, its allocations, meta-data.
TsDemuxTxDemux: Demultiplexes different types of input messages and routes them to the right destination
uncertified non-mutating query: Asks one or multiple nodes about uncertified data and takes the node’s word.
user: Depending on context, any entity that interacts with the Internet Computer platform but is not a direct participant in network operations might be referred to a user. For example, while participants might include nodes, data center providers, and neuron stakeholders, users might include end-users, third-party developers, and server operators.
valid set rule: The set of checks that every ingress message and canister message from a finalized batch must pass before it can be added to the appropriate application input queue in the induction pool.
WebAssembly:
